from fastapi import FastAPI, File, UploadFile, HTTPException
@app.on_event("startup")
async def load_models():
    global feature_extractor, generalist_model, specialist_model, label_encoder
    
    try:
        print("Loading models...")
        # Create VGG-Face model for feature extraction
        feature_extractor = create_vgg_face_model()
        feature_extractor.trainable = False
        print("✅ VGG-Face feature extractor created")astapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import tensorflow as tf
from tensorflow.keras import layers, models, applications
import numpy as np
import pickle
import os
from PIL import Image
import io
from sklearn.preprocessing import LabelEncoder

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with your frontend domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/templates", StaticFiles(directory="templates"), name="templates")

# Define age groups to match training (4 groups)
AGE_GROUPS = {
    '01_Child': (1, 17),
    '02_YoungAdult': (18, 35),
    '03_MiddleAge': (36, 55),
    '04_Senior': (56, 90)  # Capped at 90 for more realistic predictions
}

from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

def create_vgg_face_model():
    """Create VGGFace model using the keras-vggface library"""
    base_model = VGGFace(model='vgg16', include_top=False, 
                        input_shape=(224, 224, 3), 
                        pooling='avg')
    
    # Add our feature extraction layers
    x = base_model.output
    x = layers.Dense(4096, activation='relu', name='fc6')(x)
    x = layers.Dense(4096, activation='relu', name='fc7')(x)
    
    # Create model
    model = models.Model(inputs=base_model.input, outputs=x)
    return model

# Load models at startup
@app.on_event("startup")
async def load_models():
    global feature_extractor, generalist_model, specialist_model, label_encoder
    
    try:
        print("Loading models...")
        # Create and load VGG-Face model with weights
        feature_extractor = create_vgg_face_model()
        feature_extractor.load_weights('models/vgg_face_weights.h5')
        feature_extractor = tf.keras.Model(inputs=feature_extractor.input, 
                                         outputs=feature_extractor.get_layer('fc7').output)
        feature_extractor.trainable = False
        print("✅ VGG-Face feature extractor loaded")
        
        # Load the Generalist model
        generalist_model = tf.keras.models.load_model('models/generalist_model.h5')
        print("✅ Generalist model loaded")
        
        # Load Label Encoder
        with open('models/label_encoder.pkl', 'rb') as f:
            label_encoder = pickle.load(f)
        print("✅ Label encoder loaded")
        
        # Load the Specialist model
        specialist_model = tf.keras.models.load_model('models/specialist_model.h5')
        print("✅ Specialist model loaded")
        
    except Exception as e:
        print(f"❌ Error loading models: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error loading models: {str(e)}")

def preprocess_image(image_bytes):
    """Preprocess image bytes for VGG-Face model input"""
    try:
        # Open image from bytes
        img = Image.open(io.BytesIO(image_bytes))
        
        # Convert to RGB if necessary
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Resize to model's expected size
        img = img.resize((224, 224), Image.Resampling.LANCZOS)
        
        # Convert to array
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = np.expand_dims(img_array, 0)
        
        # Preprocess input specifically for VGGFace
        img_array = preprocess_input(img_array, version=1)  # version=1 for VGG16
        
        return img_array
        
    except Exception as e:
        print(f"Error in image preprocessing: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Error processing image: {str(e)}")
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Error processing image: {str(e)}")

@app.get("/", response_class=HTMLResponse)
async def read_root():
    """Serve the main HTML page"""
    with open("templates/index.html", encoding='utf-8') as f:
        return HTMLResponse(content=f.read(), status_code=200)

@app.post("/predict-age/")
async def predict_age(image: UploadFile = File(...)):
    """
    Three-step age prediction process:
    1. Extract facial features using EfficientNetV2B0
    2. Predict age group using Generalist model
    3. Predict precise age using Specialist model
    """
    try:
        # Step 1: Read and preprocess the image
        try:
            contents = await image.read()
            processed_image = preprocess_image(contents)
        except Exception as e:
            print(f"Error preprocessing image: {str(e)}")
            raise HTTPException(status_code=400, detail=f"Image preprocessing error: {str(e)}")
        
        # Step 2: Extract and adapt features
        try:
            print("\nExtracting features...")
            # Get features from fc7 layer (4096-dimensional vector)
            features = feature_extractor(processed_image, training=False)
            print(f"Features shape: {features.shape}")
            
            # Ensure features are in the correct shape (batch_size, 4096)
            if len(features.shape) == 4:  # If output is still in conv format
                features = tf.keras.layers.Flatten()(features)
            features = tf.reshape(features, (1, -1))  # Ensure batch dimension
            print(f"Final features shape: {features.shape}")
        except Exception as e:
            print(f"Error extracting features: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Feature extraction error: {str(e)}")
        
        # Step 3: Get age group prediction from generalist model
        try:
            print("\nPredicting age group...")
            range_prediction = generalist_model(features, training=False)
            predicted_range_idx = np.argmax(range_prediction[0])
            predicted_range = label_encoder.inverse_transform([predicted_range_idx])[0]
            print(f"Predicted age group: {predicted_range}")
            
            # Get the bounds for predicted age range
            min_age, max_age = AGE_GROUPS[predicted_range]
            print(f"Age range bounds: {min_age}-{max_age}")
        except Exception as e:
            print(f"Error in generalist model prediction: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Age group prediction error: {str(e)}")
        
        # Step 4: Get specific age prediction from specialist model
        try:
            print("\nPredicting specific age...")
            age_group_one_hot = tf.keras.utils.to_categorical([predicted_range_idx], num_classes=len(AGE_GROUPS))
            specialist_inputs = [features, age_group_one_hot]
            age_prediction = specialist_model(specialist_inputs, training=False)
            
            # Extract raw prediction value
            raw_output = float(age_prediction[0][0])
            print(f"Raw specialist output: {raw_output}")
            
            # Get specialist model raw prediction
            raw_output = float(age_prediction[0][0])
            print(f"\nModel Outputs:")
            print(f"Specialist raw output: {raw_output}")
            
            # Print age group probabilities
            print("\nAge Group Probabilities:")
            group_probs = []
            for i, prob in enumerate(range_prediction[0]):
                group_name = label_encoder.inverse_transform([i])[0]
                print(f"{group_name}: {prob:.4f}")
                group_probs.append(float(prob))
            
            # Get the top 2 most likely age groups
            top_2_groups = np.argsort(group_probs)[-2:]
            print(f"\nTop 2 age groups:")
            for idx in top_2_groups:
                group_name = label_encoder.inverse_transform([idx])[0]
                print(f"{group_name}: {group_probs[idx]:.4f}")
            
            # Calculate age based on the predicted age group
            min_age, max_age = AGE_GROUPS[predicted_range]
            age_range = max_age - min_age
            
            # Convert specialist model output to age
            # The specialist model should output a value between -1 and 1
            # We'll use a sigmoid-like function to ensure smooth scaling
            relative_position = 1 / (1 + np.exp(-raw_output))  # Convert to 0-1 range
            print(f"\nAge Calculation:")
            print(f"Age group range: {min_age}-{max_age}")
            print(f"Relative position in range: {relative_position:.4f}")
            
            # Calculate age within the range
            predicted_age = min_age + (age_range * relative_position)
            predicted_age = round(float(predicted_age))
            
            # Ensure prediction stays within group bounds
            predicted_age = np.clip(predicted_age, min_age, max_age)
            print(f"Final predicted age: {predicted_age}")
            
            # Calculate confidence
            # Base it on both the age group probability and how close to range boundaries
            group_confidence = float(range_prediction[0][predicted_range_idx])
            
            # Lower confidence if close to range boundaries
            relative_pos_in_range = (predicted_age - min_age) / age_range
            boundary_penalty = 1.0 - (2 * abs(relative_pos_in_range - 0.5))
            boundary_penalty = max(0.5, boundary_penalty)  # Don't reduce confidence below 50%
            
            # Final confidence calculation
            confidence = float(group_confidence * boundary_penalty * 100)
            confidence = min(95.0, max(10.0, confidence))  # Keep confidence between 10% and 95%
            print(f"\nConfidence calculation:")
            print(f"Group confidence: {group_confidence:.4f}")
            print(f"Boundary penalty: {boundary_penalty:.4f}")
            print(f"Final confidence: {confidence:.1f}%")
            
            print(f"Final prediction: Age {predicted_age}, Group {predicted_range}, Confidence {confidence:.1f}%")
            
            # Verify outputs are valid
            if np.isnan(predicted_age) or np.isnan(confidence):
                raise ValueError("Prediction resulted in NaN values")
            
            # Convert numpy types to Python native types
            return JSONResponse({
                'age_group': str(predicted_range),
                'predicted_age': int(predicted_age),
                'confidence': float(confidence)
            })
            
        except Exception as e:
            error_msg = str(e)
            if not error_msg:
                error_msg = "Unknown error during prediction"
            print(f"Error in final prediction step: {error_msg}")
            raise HTTPException(status_code=500, detail=f"Age prediction error: {error_msg}")
            
    except HTTPException as he:
        if not he.detail:
            he.detail = "Unknown error occurred"
        raise he
    except Exception as e:
        error_msg = str(e)
        if not error_msg:
            error_msg = "Unexpected error during prediction"
        print(f"Unexpected error: {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8003)  # Changed port to 8003